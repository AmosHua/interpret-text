{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright (c) Microsoft Corporation. All rights reserved.*\n",
    "\n",
    "*Licensed under the MIT License.*\n",
    "\n",
    "# Text Classification of SST-2 Sentences using BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before You Start\n",
    "\n",
    "> **Tip**: If you want to run through the notebook quickly, you can set the **`QUICK_RUN`** flag in the cell below to **`True`**. This will run the notebook on a small subset of the data and a use a smaller number of epochs. \n",
    "\n",
    "If you run into CUDA out-of-memory error or the jupyter kernel dies constantly, try reducing the `BATCH_SIZE` and `MAX_LEN`, but note that model performance will be compromised. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set QUICK_RUN = True to run the notebook on a small subset of data and a smaller number of epochs.\n",
    "QUICK_RUN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0109 11:10:53.883785 140364218693440 file_utils.py:37] PyTorch version 1.3.1 available.\n",
      "/home/maidap/anaconda3/envs/interpret_cpu_extern/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/maidap/anaconda3/envs/interpret_cpu_extern/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/maidap/anaconda3/envs/interpret_cpu_extern/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/maidap/anaconda3/envs/interpret_cpu_extern/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/maidap/anaconda3/envs/interpret_cpu_extern/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/maidap/anaconda3/envs/interpret_cpu_extern/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "I0109 11:10:54.877334 140364218693440 modeling.py:230] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scrapbook as sb\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from utils_nlp.dataset.multinli import load_pandas_df \n",
    "from utils_nlp.models.bert.sequence_classification import BERTSequenceClassifier\n",
    "from utils_nlp.models.bert.common import Language, Tokenizer\n",
    "from utils_nlp.common.timer import Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret_text.msra.MSRAExplainer import MSRAExplainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this notebook, we fine-tune and evaluate a pretrained [BERT](https://arxiv.org/abs/1810.04805) model on a subset of the [SST-2](https://nlp.stanford.edu/sentiment/index.html/) dataset. To run this notebook, we used the SST-2 data files provided [here](https://github.com/AcademiaSinicaNLPLab/sentiment_dataset). You should download files matching data/sst2.binary.* into a folder and point DATA_FOLDER (below) to that folder.\n",
    "\n",
    "We use a [sequence classifier](https://github.com/microsoft/nlp/blob/master/utils_nlp/models/bert/sequence_classification.py) that wraps [Hugging Face's PyTorch implementation](https://github.com/huggingface/pytorch-pretrained-BERT) of Google's [BERT](https://github.com/google-research/bert)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters\n",
    "Here we set some parameters that we use for our modeling task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_FRACTION = 1\n",
    "TEST_DATA_FRACTION = 1\n",
    "NUM_EPOCHS = 1\n",
    "\n",
    "if QUICK_RUN:\n",
    "    TRAIN_DATA_FRACTION = 0.01\n",
    "    TEST_DATA_FRACTION = 0.01\n",
    "    NUM_EPOCHS = 1\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    BATCH_SIZE = 32\n",
    "else:\n",
    "    BATCH_SIZE = 8\n",
    "\n",
    "DATA_FOLDER = \"../../../data/sst2\"\n",
    "BERT_CACHE_DIR = \"./temp/sst2\"\n",
    "LANGUAGE = Language.ENGLISH\n",
    "TO_LOWER = True\n",
    "MAX_LEN = 150\n",
    "BATCH_SIZE_PRED = 512\n",
    "TRAIN_SIZE = 0.6\n",
    "LABEL_COL = \"labels\" \n",
    "TEXT_COL = \"sentences\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Dataset\n",
    "We start by loading a subset of the data. The following function also downloads and extracts the files, if they don't exist in the data folder.\n",
    "\n",
    "The SST-2 dataset is dataset of Rotten Tomatoes movie reviews mainly used for natural language inference (NLI) tasks, where the inputs are sentences and the labels are binary (positive or negative) sentiment indicators. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading the data for training and testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fpath):\n",
    "    df_dict = {LABEL_COL: [], TEXT_COL: []}\n",
    "    with open(fpath, 'r') as f:\n",
    "        label_start = 0\n",
    "        sentence_start = 2\n",
    "        for line in f:\n",
    "            label = int(line[label_start])\n",
    "            sentence = line[sentence_start:]\n",
    "            df_dict['labels'].append(label)\n",
    "            df_dict['sentences'].append(sentence)\n",
    "    return pd.DataFrame.from_dict(df_dict)\n",
    "\n",
    "df_train = load_data(os.path.join(DATA_FOLDER, 'stsa.binary.train'))\n",
    "df_test = load_data(os.path.join(DATA_FOLDER, 'stsa.binary.test'))\n",
    "\n",
    "\n",
    "if QUICK_RUN:\n",
    "    df_train = df_train.sample(frac=TRAIN_DATA_FRACTION).reset_index(drop=True)\n",
    "    df_test = df_test.sample(frac=TEST_DATA_FRACTION).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the two classes in the dataset, where \"1\" corresponds to a positive review and \"0\" corresponds to a negative review. We don't need to encode the labels as they are already integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   labels                                          sentences\n",
      "0       1  strange occurrences build in the mind of the v...\n",
      "1       1  jones ... makes a great impression as the writ...\n",
      "2       0  at best , cletis tout might inspire a trip to ...\n",
      "3       0  with a romantic comedy plotline straight from ...\n",
      "4       1  enough may pander to our basest desires for pa...\n",
      "1    35\n",
      "0    34\n",
      "Name: labels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# display stats and examples for label types\n",
    "print(df_train[[LABEL_COL, TEXT_COL]].head())\n",
    "print(df_train[LABEL_COL].value_counts())\n",
    "\n",
    "# create training and testing labels\n",
    "labels_train = df_train[LABEL_COL]\n",
    "labels_test = df_test[LABEL_COL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique labels: 2\n",
      "Number of training examples: 69\n",
      "Number of testing examples: 18\n"
     ]
    }
   ],
   "source": [
    "num_labels = len(np.unique(labels_train))\n",
    "print(\"Number of unique labels: {}\".format(num_labels))\n",
    "print(\"Number of training examples: {}\".format(df_train.shape[0]))\n",
    "print(\"Number of testing examples: {}\".format(df_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start training, we tokenize the text documents and convert them to lists of tokens. The following steps instantiate a `BERT tokenizer` given the language, and tokenize the text of the training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0109 11:29:38.392958 140364218693440 file_utils.py:224] https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache, downloading to /tmp/tmpyicdmvao\n",
      "100%|██████████| 231508/231508 [00:00<00:00, 4641185.61B/s]\n",
      "I0109 11:29:38.580375 140364218693440 file_utils.py:237] copying /tmp/tmpyicdmvao to cache at ./temp/sst2/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "I0109 11:29:38.582956 140364218693440 file_utils.py:241] creating metadata file for ./temp/sst2/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "I0109 11:29:38.587434 140364218693440 file_utils.py:250] removing temp file /tmp/tmpyicdmvao\n",
      "I0109 11:29:38.589242 140364218693440 tokenization.py:190] loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./temp/sst2/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "100%|██████████| 69/69 [00:00<00:00, 3372.73it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 2731.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['strange', 'occurrences', 'build', 'in', 'the', 'mind', 'of', 'the', 'viewer', 'and', 'take', 'on', 'extreme', 'urgency', '.'], ['jones', '.', '.', '.', 'makes', 'a', 'great', 'impression', 'as', 'the', 'writer', '-', 'director', 'of', 'this', 'little', '$', '1', '.', '8', 'million', 'charm', '##er', ',', 'which', 'may', 'not', 'be', 'cutting', '-', 'edge', 'indie', 'filmmaking', 'but', 'has', 'a', 'huge', 'heart', '.'], ['at', 'best', ',', 'cl', '##eti', '##s', 'to', '##ut', 'might', 'inspire', 'a', 'trip', 'to', 'the', 'video', 'store', '-', '-', 'in', 'search', 'of', 'a', 'better', 'movie', 'experience', '.'], ['with', 'a', 'romantic', 'comedy', 'plot', '##line', 'straight', 'from', 'the', 'ages', ',', 'this', 'cinderella', 'story', 'does', 'n', \"'\", 't', 'have', 'a', 'single', 'surprise', 'up', 'its', 'sleeve', '.'], ['enough', 'may', 'pan', '##der', 'to', 'our', 'bases', '##t', 'desires', 'for', 'pay', '##back', ',', 'but', 'unlike', 'many', 'revenge', 'fantasies', ',', 'it', 'ultimately', 'delivers', '.'], ['sh', '##rew', '##d', 'but', 'pointless', '.'], ['in', 'its', 'own', 'fl', '##ound', '##ering', 'way', ',', 'it', 'gets', 'to', 'you', '.'], ['ring', '##u', 'is', 'a', 'disaster', 'of', 'a', 'story', ',', 'full', 'of', 'holes', 'and', 'completely', 'lacking', 'in', 'chill', '##s', '.'], ['it', 'celebrates', 'the', 'group', \"'\", 's', 'playful', 'spark', 'of', 'non', '##con', '##form', '##ity', ',', 'glancing', 'vivid', '##ly', 'back', 'at', 'what', 'hi', '##bis', '##cus', 'grand', '##ly', 'called', 'his', '`', 'angels', 'of', 'light', '.', \"'\"], ['the', 'jokes', 'are', 'telegraph', '##ed', 'so', 'far', 'in', 'advance', 'they', 'must', 'have', 'been', 'lost', 'in', 'the', 'mail', '.'], ['a', 'bland', 'animated', 'sequel', 'that', 'hardly', 'seems', 'worth', 'the', 'effort', '.'], ['i', 'liked', 'this', 'film', 'a', 'lot', '.', '.', '.'], ['it', 'has', 'no', 'affect', 'on', 'the', 'ku', '##rds', ',', 'but', 'it', 'wore', 'me', 'down', '.'], ['the', 'action', 'here', 'is', 'unusually', 'tame', ',', 'the', 'characters', 'are', 'too', 'sim', '##pl', '##istic', 'to', 'maintain', 'interest', ',', 'and', 'the', 'plot', 'offers', 'few', 'surprises', '.'], ['many', 'went', 'to', 'see', 'the', 'attraction', 'for', 'the', 'sole', 'reason', 'that', 'it', 'was', 'hot', 'outside', 'and', 'there', 'was', 'air', 'conditioning', 'inside', ',', 'and', 'i', 'do', 'n', \"'\", 't', 'think', 'that', 'a', '.', 'c', '.', 'will', 'help', 'this', 'movie', 'one', 'bit', '.'], ['although', 'este', '##la', 'bravo', \"'\", 's', 'documentary', 'is', 'cl', '##oy', '##ingly', 'ha', '##gio', '##graphic', 'in', 'its', 'portrait', 'of', 'cuban', 'leader', 'fide', '##l', 'castro', ',', 'it', \"'\", 's', 'still', 'a', 'guilty', 'pleasure', 'to', 'watch', '.'], ['a', 'real', 'audience', '-', 'please', '##r', 'that', 'will', 'strike', 'a', 'chord', 'with', 'anyone', 'who', \"'\", 's', 'ever', 'waited', 'in', 'a', 'doctor', \"'\", 's', 'office', ',', 'emergency', 'room', ',', 'hospital', 'bed', 'or', 'insurance', 'company', 'office', '.'], ['a', 'fake', 'street', 'drama', 'that', 'keeps', 'telling', 'you', 'things', 'instead', 'of', 'showing', 'them', '.'], ['the', 'first', 'bond', 'movie', 'in', 'ages', 'that', 'is', 'n', \"'\", 't', 'fake', 'fun', '.'], ['a', 'harrow', '##ing', 'account', 'of', 'a', 'psychological', 'breakdown', '.'], ['hailed', 'as', 'a', 'clever', 'exercise', 'in', 'neo', '-', 'hitchcock', '##iani', '##sm', ',', 'this', 'clever', 'and', 'very', 'satisfying', 'picture', 'is', 'more', 'accurately', 'cha', '##bro', '##lian', '.'], ['unlike', 'lots', 'of', 'hollywood', 'flu', '##ff', ',', 'this', 'has', 'layered', ',', 'well', '-', 'developed', 'characters', 'and', 'some', 'surprises', '.'], ['surprisingly', 'powerful', 'and', 'universal', '.'], ['a', 'grit', '##ti', '##ly', 'beautiful', 'film', 'that', 'looks', ',', 'sounds', ',', 'and', 'feels', 'more', 'like', 'an', 'extended', ',', 'open', '-', 'ended', 'poem', 'than', 'a', 'traditionally', 'structured', 'story', '.'], ['kids', 'will', 'love', 'its', 'fantasy', 'and', 'adventure', ',', 'and', 'grown', '##ups', 'should', 'appreciate', 'its', 'w', '##him', '##sic', '##al', 'humor', '.'], ['it', \"'\", 's', 'an', 'interesting', 'effort', '-', 'l', '##rb', '-', 'particularly', 'for', 'j', '##fk', 'conspiracy', 'nuts', '-', 'rr', '##b', '-', ',', 'and', 'barry', \"'\", 's', 'cold', '-', 'fish', 'act', 'makes', 'the', 'experience', 'worth', '##while', '.'], ['.', '.', '.', 'the', 'whole', 'thing', 'succeeded', 'only', 'in', 'making', 'me', 'gr', '##og', '##gy', '.'], ['a', 'beyond', '-', 'lame', 'satire', ',', 'teddy', 'bears', \"'\", 'picnic', 'ranks', 'among', 'the', 'most', 'pit', '##iful', 'directing', 'debuts', 'by', 'an', 'esteem', '##ed', 'writer', '-', 'actor', '.'], [',', 'is', 'a', 'temporal', 'inquiry', 'that', 'shoulders', 'its', 'philosophical', 'burden', 'lightly', '.'], ['for', 've', '##gg', '##ie', '##tale', '##s', 'fans', ',', 'this', 'is', 'more', 'app', '##eti', '##zing', 'than', 'a', 'side', 'dish', 'of', 'as', '##para', '##gus', '.'], ['fred', 'sc', '##he', '##pis', '##i', \"'\", 's', 'tale', 'of', 'four', 'english', '##men', 'facing', 'the', 'prospect', 'of', 'their', 'own', 'mortality', 'views', 'youthful', 'af', '##fl', '##uen', '##ce', 'not', 'as', 'a', 'lost', 'ideal', 'but', 'a', 'starting', 'point', '.'], ['no', 'big', 'who', '##op', ',', 'nothing', 'new', 'to', 'see', ',', 'zero', 'thrill', '##s', ',', 'too', 'many', 'flashbacks', 'and', 'a', 'chop', '##py', 'ending', 'make', 'for', 'a', 'bad', 'film', '.'], ['as', 'steam', '##y', 'as', 'last', 'week', \"'\", 's', 'pork', 'dump', '##lings', '.'], ['like', 'a', 'skill', '##ful', 'fisher', ',', 'the', 'director', 'uses', 'the', 'last', 'act', 'to', 'reel', 'in', 'the', 'audience', 'since', 'its', 'po', '##ign', '##ancy', 'hooks', 'us', 'completely', '.'], ['the', 'cast', 'is', 'top', '-', 'notch', 'and', 'i', 'predict', 'there', 'will', 'be', 'plenty', 'of', 'female', 'audience', 'members', 'dr', '##ool', '##ing', 'over', 'michael', 'id', '##em', '##oto', 'as', 'michael', '.'], ['an', 'emotionally', 'strong', 'and', 'politically', 'potent', 'piece', 'of', 'cinema', '.'], ['once', 'one', 'experiences', 'mr', '.', 'han', '##eke', \"'\", 's', 'own', 'sad', '##istic', 'tendencies', 'toward', 'his', 'audience', ',', 'one', 'is', 'left', 'with', 'a', 'sour', 'taste', 'in', 'one', \"'\", 's', 'mouth', ',', 'and', 'little', 'else', '.'], ['an', 'uneven', 'look', 'into', 'a', 'grim', 'future', 'that', 'does', 'n', \"'\", 't', 'come', 'close', 'to', 'the', 'level', 'of', 'intelligence', 'and', 'visual', 'sp', '##len', '##dou', '##r', 'that', 'can', 'be', 'seen', 'in', 'other', 'films', 'based', 'on', 'philip', 'k', '.', 'dick', 'stories', '.'], ['but', 'it', 'will', 'just', 'as', 'likely', 'make', 'you', 'weep', ',', 'and', 'it', 'will', 'do', 'so', 'in', 'a', 'way', 'that', 'does', 'n', \"'\", 't', 'make', 'you', 'feel', 'like', 'a', 'sucker', '.'], ['the', 'acting', 'is', 'just', 'fine', ',', 'but', 'there', \"'\", 's', 'not', 'enough', 'substance', 'here', 'to', 'sustain', 'interest', 'for', 'the', 'full', '90', 'minutes', ',', 'especially', 'with', 'the', 'weak', 'pay', '##off', '.'], ['the', 'search', 'for', 'redemption', 'makes', 'for', 'a', 'touching', 'love', 'story', ',', 'mainly', 'because', 'blanche', '##tt', 'and', 'rib', '##isi', 'compelling', '##ly', 'tap', 'into', 'a', 'spiritual', 'aspect', 'of', 'their', 'characters', \"'\", 'suffering', '.'], ['such', 'a', 'bad', 'movie', 'that', 'its', 'luck', '##iest', 'viewers', 'will', 'be', 'seated', 'next', 'to', 'one', 'of', 'those', 'ignorant', 'pin', '##heads', 'who', 'talk', 'throughout', 'the', 'show', '.'], ['a', 'marvelous', 'performance', 'by', 'allison', 'lo', '##hman', 'as', 'an', 'identity', '-', 'seeking', 'foster', 'child', '.'], ['funny', ',', 'somber', ',', 'absurd', ',', 'and', ',', 'finally', ',', 'aching', '##ly', 'sad', ',', 'bart', '##le', '##by', 'is', 'a', 'fine', ',', 'under', '##sta', '##ted', 'piece', 'of', 'filmmaking', '.'], ['and', 'it', \"'\", 's', 'not', 'that', 'funny', '-', '-', 'which', 'is', 'just', 'generally', 'insulting', '.'], ['a', 'fascinating', 'documentary', 'about', 'the', 'long', 'and', 'event', '##ful', 'spiritual', 'journey', 'of', 'the', 'guru', 'who', 'helped', 'launch', 'the', 'new', 'age', '.'], ['the', 'code', 'talk', '##ers', 'deserved', 'better', 'than', 'a', 'hollow', 'tribute', '.'], ['charlotte', 'sometimes', 'is', 'a', 'gem', '.'], ['everything', '-', '-', 'even', 'life', 'on', 'an', 'aircraft', 'carrier', '-', '-', 'is', 'sentimental', '##ized', '.'], ['gorgeous', 'to', 'look', 'at', 'but', 'ins', '##uf', '##fera', '##bly', 'ted', '##ious', 'and', 'tu', '##rg', '##id', '.', '.', '.', 'a', 'curiously', 'con', '##st', '##ricted', 'epic', '.'], ['the', 'emperor', \"'\", 's', 'club', ',', 'ruthless', 'in', 'its', 'own', 'pl', '##ac', '##id', 'way', ',', 'finds', 'one', 'of', 'our', 'most', 'conservative', 'and', 'hide', '##bound', 'movie', '-', 'making', 'traditions', 'and', 'gives', 'it', 'new', 'texture', ',', 'new', 'relevance', ',', 'new', 'reality', '.'], ['too', 'much', 'of', 'nemesis', 'has', 'a', 'tired', ',', 'talk', '##y', 'feel', '.'], ['implicit', '##ly', 'acknowledges', 'and', 'celebrates', 'the', 'glorious', 'chi', '##can', '##ery', 'and', 'self', '-', 'del', '##usion', 'of', 'this', 'most', 'american', 'of', 'businesses', ',', 'and', 'for', 'that', 'reason', 'it', 'may', 'be', 'the', 'most', 'oddly', 'honest', 'hollywood', 'document', 'of', 'all', '.'], ['in', '##vent', '##ive', ',', 'fun', ',', 'into', '##xi', '##cating', '##ly', 'sexy', ',', 'violent', ',', 'self', '-', 'ind', '##ul', '##gent', 'and', 'madden', '##ing', '.'], ['the', 'story', 'itself', 'is', 'actually', 'quite', 'va', '##pid', '.'], ['it', \"'\", 's', 'the', 'cute', 'fr', '##isson', '##s', 'of', 'discovery', 'and', 'humor', 'between', 'chaplin', 'and', 'kid', '##man', 'that', 'keep', 'this', 'nicely', 'wound', 'clock', 'not', 'just', 'ticking', ',', 'but', 'humming', '.'], ['if', 'the', 'last', 'man', 'were', 'the', 'last', 'movie', 'left', 'on', 'earth', ',', 'there', 'would', 'be', 'a', 'toss', '-', 'up', 'between', 'presiding', 'over', 'the', 'end', 'of', 'cinema', 'as', 'we', 'know', 'it', 'and', 'another', 'night', 'of', 'delightful', 'hand', 'shadows', '.'], ['a', 'film', 'without', 'surprise', 'geared', 'toward', 'maximum', 'comfort', 'and', 'familiarity', '.'], ['.', '.', '.', 'better', 'described', 'as', 'a', 'ghost', 'story', 'gone', 'badly', 'aw', '##ry', '.'], ['what', 'more', 'can', 'be', 'expected', 'from', 'a', 'college', 'comedy', 'that', \"'\", 's', 'target', 'audience', 'has', 'n', \"'\", 't', 'graduated', 'from', 'junior', 'high', 'school', '?'], ['michael', 'moore', 'has', 'perfect', '##ed', 'the', 'art', 'of', 'highly', 'entertaining', ',', 'self', '-', 'ag', '##gra', '##ndi', '##zing', ',', 'politically', 'motivated', 'documentary', '-', 'making', ',', 'and', 'he', \"'\", 's', 'got', 'as', 'potent', 'a', 'topic', 'as', 'ever', 'here', '.'], ['this', 'story', 'of', 'a', 'determined', 'woman', \"'\", 's', 'courage', 'to', 'find', 'her', 'husband', 'in', 'a', 'war', 'zone', 'offers', 'winning', 'performances', 'and', 'some', 'effect', '##ing', 'moments', '.'], ['the', 'attempt', 'to', 'build', 'up', 'a', 'pressure', 'cooke', '##r', 'of', 'horrified', 'awe', 'emerges', 'from', 'the', 'simple', 'fact', 'that', 'the', 'movie', 'has', 'virtually', 'nothing', 'to', 'show', '.'], ['the', 'trapping', '##s', 'of', 'i', 'spy', 'are', 'so', 'familiar', 'you', 'might', 'as', 'well', 'be', 'watching', 'a', 're', '##run', '.'], ['a', 'so', '-', 'so', ',', 'made', '-', 'for', '-', 'tv', 'something', 'posing', 'as', 'a', 'real', 'movie', '.'], ['the', 'movie', 'is', 'about', 'as', 'deep', 'as', 'that', 'sentiment', '.'], ['one', 'of', 'the', 'worst', 'movies', 'of', 'the', 'year', '.'], ['the', 'film', 'does', 'give', 'a', 'pretty', 'good', 'overall', 'picture', 'of', 'the', 'situation', 'in', 'lara', '##mie', 'following', 'the', 'murder', 'of', 'matthew', 'shepard', '.'], ['what', \"'\", 's', 'missing', 'in', 'murder', 'by', 'numbers', 'is', 'any', 'real', 'psychological', 'ground', '##ing', 'for', 'the', 'teens', \"'\", 'devi', '##ant', 'behaviour', '.']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(LANGUAGE, to_lower=TO_LOWER, cache_dir=BERT_CACHE_DIR)\n",
    "\n",
    "tokens_train = tokenizer.tokenize(list(df_train[TEXT_COL]))\n",
    "tokens_test = tokenizer.tokenize(list(df_test[TEXT_COL]))\n",
    "\n",
    "print(tokens_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we perform the following preprocessing steps in the cell below:\n",
    "- Convert the tokens into token indices corresponding to the BERT tokenizer's vocabulary\n",
    "- Add the special tokens [CLS] and [SEP] to mark the beginning and end of a sentence, respectively\n",
    "- Pad or truncate the token lists to the specified max length. In this case, `MAX_LEN = 150`\n",
    "- Return mask lists that indicate the paddings' positions\n",
    "- Return token type id lists that indicate which sentence the tokens belong to (not needed for one-sequence classification)\n",
    "\n",
    "*See the original [implementation](https://github.com/google-research/bert/blob/master/run_classifier.py) for more information on BERT's input format.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_train, mask_train, _ = tokenizer.preprocess_classification_tokens(tokens_train, MAX_LEN)\n",
    "tokens_test, mask_test, _ = tokenizer.preprocess_classification_tokens(tokens_test, MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Classifier Model\n",
    "Next, we use a sequence classifier that loads a pre-trained BERT model, given the language and number of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0109 11:29:44.866021 140364218693440 file_utils.py:224] https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz not found in cache, downloading to /tmp/tmp7jzo78pr\n",
      "100%|██████████| 407873900/407873900 [00:04<00:00, 81875997.02B/s]\n",
      "I0109 11:29:49.974365 140364218693440 file_utils.py:237] copying /tmp/tmp7jzo78pr to cache at ./temp/sst2/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "I0109 11:29:50.376198 140364218693440 file_utils.py:241] creating metadata file for ./temp/sst2/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "I0109 11:29:50.377841 140364218693440 file_utils.py:250] removing temp file /tmp/tmp7jzo78pr\n",
      "I0109 11:29:50.440929 140364218693440 modeling.py:580] loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at ./temp/sst2/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "I0109 11:29:50.442383 140364218693440 modeling.py:588] extracting archive file ./temp/sst2/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmptm6gd86a\n",
      "I0109 11:29:53.892902 140364218693440 modeling.py:598] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0109 11:29:56.914633 140364218693440 modeling.py:648] Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "I0109 11:29:56.916261 140364218693440 modeling.py:651] Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    }
   ],
   "source": [
    "classifier = BERTSequenceClassifier(language=LANGUAGE, num_labels=num_labels, cache_dir=BERT_CACHE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "We train the classifier using the training set. This involves fine-tuning the BERT Transformer and learning a linear classification layer on top of that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0109 11:29:56.929049 140364218693440 optimization.py:46] t_total value of -1 results in schedule not being applied\n",
      "Iteration:  11%|█         | 1/9 [00:03<00:27,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1/1; batch:1->1/9; average training loss:0.671034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Iteration:  22%|██▏       | 2/9 [00:06<00:22,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1/1; batch:2->2/9; average training loss:0.655887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Iteration:  33%|███▎      | 3/9 [00:08<00:18,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1/1; batch:3->3/9; average training loss:0.706290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Iteration:  44%|████▍     | 4/9 [00:12<00:16,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1/1; batch:4->4/9; average training loss:0.696389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Iteration:  56%|█████▌    | 5/9 [00:16<00:13,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1/1; batch:5->5/9; average training loss:0.695839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Iteration:  67%|██████▋   | 6/9 [00:18<00:09,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1/1; batch:6->6/9; average training loss:0.682462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Iteration:  78%|███████▊  | 7/9 [00:21<00:05,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1/1; batch:7->7/9; average training loss:0.680790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Iteration:  89%|████████▉ | 8/9 [00:23<00:02,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1/1; batch:8->8/9; average training loss:0.689766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Iteration: 100%|██████████| 9/9 [00:26<00:00,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1/1; batch:9->9/9; average training loss:0.691330\n",
      "[Training time: 0.007 hrs]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with Timer() as t:\n",
    "    classifier.fit(token_ids=tokens_train,\n",
    "                    input_mask=mask_train,\n",
    "                    labels=labels_train,    \n",
    "                    num_epochs=NUM_EPOCHS,\n",
    "                    batch_size=BATCH_SIZE,    \n",
    "                    verbose=True)    \n",
    "print(\"[Training time: {:.3f} hrs]\".format(t.interval / 3600))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Model\n",
    "We score the test set using the trained classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1/1 [00:01<00:00,  1.56s/it]\n"
     ]
    }
   ],
   "source": [
    "preds = classifier.predict(token_ids=tokens_test, \n",
    "                           input_mask=mask_test, \n",
    "                           batch_size=BATCH_SIZE_PRED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model\n",
    "Finally, we compute the overall accuracy, precision, recall, and F1 metrics on the test set. We also look at the metrics for eact of the genres in the the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.3333333333333333\n",
      "{\n",
      "    \"0\": {\n",
      "        \"f1-score\": 0.5,\n",
      "        \"precision\": 0.3333333333333333,\n",
      "        \"recall\": 1.0,\n",
      "        \"support\": 6\n",
      "    },\n",
      "    \"1\": {\n",
      "        \"f1-score\": 0.0,\n",
      "        \"precision\": 0.0,\n",
      "        \"recall\": 0.0,\n",
      "        \"support\": 12\n",
      "    },\n",
      "    \"macro avg\": {\n",
      "        \"f1-score\": 0.25,\n",
      "        \"precision\": 0.16666666666666666,\n",
      "        \"recall\": 0.5,\n",
      "        \"support\": 18\n",
      "    },\n",
      "    \"micro avg\": {\n",
      "        \"f1-score\": 0.3333333333333333,\n",
      "        \"precision\": 0.3333333333333333,\n",
      "        \"recall\": 0.3333333333333333,\n",
      "        \"support\": 18\n",
      "    },\n",
      "    \"weighted avg\": {\n",
      "        \"f1-score\": 0.16666666666666666,\n",
      "        \"precision\": 0.1111111111111111,\n",
      "        \"recall\": 0.3333333333333333,\n",
      "        \"support\": 18\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(labels_test, preds, target_names=[1, 0], output_dict=True) \n",
    "accuracy = accuracy_score(labels_test, preds)\n",
    "# change labels in report to strings for ease of display\n",
    "report[\"0\"] = report.pop(0)\n",
    "report[\"1\"] = report.pop(1)\n",
    "\n",
    "print(\"accuracy: {}\".format(accuracy))\n",
    "print(json.dumps(report, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": 0.3333333333333333,
       "encoder": "json",
       "name": "accuracy",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "accuracy"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": 0.16666666666666666,
       "encoder": "json",
       "name": "precision",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "precision"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": 0.5,
       "encoder": "json",
       "name": "recall",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "recall"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": 0.25,
       "encoder": "json",
       "name": "f1",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "f1"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for testing\n",
    "sb.glue(\"accuracy\", accuracy)\n",
    "sb.glue(\"precision\", report[\"macro avg\"][\"precision\"])\n",
    "sb.glue(\"recall\", report[\"macro avg\"][\"recall\"])\n",
    "sb.glue(\"f1\", report[\"macro avg\"][\"f1-score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cpu\" if not torch.cuda.is_available() else \"cuda\")\n",
    "\n",
    "classifier.model.to(device)\n",
    "for param in classifier.model.parameters():\n",
    "    param.requires_grad = False\n",
    "classifier.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter_msra = MSRAExplainer(model=classifier.model, \n",
    "                                 train_dataset=list(df_train[TEXT_COL]), \n",
    "                                 device=device, \n",
    "                                 target_layer=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mr. wedge and mr. saldanha handle the mix of verbal jokes and slapstick well .\n",
      " 1\n"
     ]
    }
   ],
   "source": [
    "text = df_test[TEXT_COL][1]\n",
    "label = df_test[LABEL_COL][1]\n",
    "print(text, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0109 11:33:21.194610 140364218693440 tokenization.py:190] loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/maidap/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "I0109 11:33:21.420469 140364218693440 tokenization.py:190] loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./temp/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "100%|██████████| 69/69 [00:00<00:00, 3399.55it/s]\n",
      "100%|██████████| 50/50 [00:29<00:00,  1.88it/s]\n"
     ]
    }
   ],
   "source": [
    "explanation_msra = interpreter_msra.explain_local(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0109 11:34:11.307861 140364218693440 tokenization.py:190] loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/maidap/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:rgba(135,206,250,0.240360713005066);\">mr</span> <span style=\"background-color:rgba(135,206,250,0.28584918975830087);\">.</span> <span style=\"background-color:rgba(135,206,250,0.5282449483871461);\">wedge</span> <span style=\"background-color:rgba(135,206,250,0.5781256318092347);\">and</span> <span style=\"background-color:rgba(250,0,0,0.25947740077972403);\">mr</span> <span style=\"background-color:rgba(250,0,0,0.2952871561050414);\">.</span> <span style=\"background-color:rgba(250,0,0,0.4642039775848388);\">sal</span> <span style=\"background-color:rgba(135,206,250,0.24120131731033334);\">##dan</span> <span style=\"background-color:rgba(250,0,0,0.5422158479690551);\">##ha</span> <span style=\"background-color:rgba(135,206,250,0.676062709093094);\">handle</span> <span style=\"background-color:rgba(135,206,250,0.127373492717743);\">the</span> <span style=\"background-color:rgba(250,0,0,0.027679586410522372);\">mix</span> <span style=\"background-color:rgba(135,206,250,0.6633499622344972);\">of</span> <span style=\"background-color:rgba(135,206,250,0.6464872419834138);\">verbal</span> <span style=\"background-color:rgba(135,206,250,0.043017125129699796);\">jokes</span> <span style=\"background-color:rgba(250,0,0,0.2594787120819091);\">and</span> <span style=\"background-color:rgba(135,206,250,0.3447243332862855);\">slap</span> <span style=\"background-color:rgba(250,0,0,0.18358602523803702);\">##stick</span> <span style=\"background-color:rgba(135,206,250,0.3890319824218751);\">well</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interpreter_msra.visualize(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (interpret_cpu)",
   "language": "python",
   "name": "interpret_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
